## 1. Graphical models

```{r}
library(bnlearn)

data("lizards")

lizardsnet<-model2network("[Species][Diameter|Species][Height|Species]") # True DAG
plot(lizardsnet)
plot(cpdag(lizardsnet)) # Plot the true pattern

ci.test("Diameter", "Species", test = "x2", data = lizards) # Keep edge D-S.
ci.test("Height", "Species", test = "x2", data = lizards) # Keep edge H-S.
ci.test("Height", "Diameter", test = "x2", data = lizards) # Remove edge D-H.
ci.test("Diameter", "Species", "Height", test = "x2", data = lizards) # Keep edge D-S.
ci.test("Height", "Species", "Diameter", test = "x2", data = lizards) # Keep edge H-S.

# Orientate D->S<-H. Wrong model !

```

## 2. HMM

```{r}

library(bnlearn)
library(gRain)

net <- model2network("[Z0][X0|Z0][Z1|Z0][X1|Z1][Z2|Z1][X2|Z2][Z3|Z2]")
graphviz.plot(net)

```

```{r}

trans_probs <- matrix(0, nrow = 10, ncol = 10)

for (i in 1:10) {
  trans_probs[i, i] <- 0.5
  next_sector <- ifelse(i == 10, 1, i + 1)
  trans_probs[i, next_sector] <- 0.5
}

emission_probs <- matrix(0, nrow = 10, ncol = 10)

for (i in 1:10) {
  sectors <- ((i - 3):(i + 1)) %% 10 + 1  # Adjust for 1-based indexing
  emission_probs[i, sectors] <- 1/5
}

cptZ0 <- c(.1,.1,.1,.1,.1,.1,.1,.1,.1,.1)
dim(cptZ0) <- c(10)
dimnames(cptZ0) <- list(c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

cptZ1 <- trans_probs
dimnames(cptZ1) <- list("Z1" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z0" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

cptZ2 <- trans_probs
dimnames(cptZ2) <- list("Z2" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z1" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

cptZ3 <- trans_probs
dimnames(cptZ3) <- list("Z3" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z2" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))


cptX0 <- emission_probs
dimnames(cptX0) <- list("X0" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z0" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

cptX1 <- emission_probs
dimnames(cptX1) <- list("X1" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z1" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

cptX2 <- emission_probs
dimnames(cptX2) <- list("X2" = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), "Z2" =  c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

netfit = custom.fit(net,list(Z0=cptZ0, Z1=cptZ1, Z2=cptZ2, Z3=cptZ3, X0=cptX0, X1=cptX1, X2=cptX2))
netcom <- compile(as.grain(netfit))

querygrain(setEvidence(netcom,nodes=c("X0","X2"), states =c("1","3")),"Z0")
querygrain(setEvidence(netcom,nodes=c("X0","X2"), states =c("1","3")),"Z1")
querygrain(setEvidence(netcom,nodes=c("X0","X2"), states =c("1","3")),"Z2")
querygrain(setEvidence(netcom,nodes=c("X0","X2"), states =c("1","3")),"Z3")

```

## Reinforement learning

given from old exam

```{r}


# install.packages("ggplot2")
# install.packages("vctrs")
library(ggplot2)

# If you do not see four arrows in line 16, then do the following:
# File/Reopen with Encoding/UTF-8

arrows <- c("↑", "→", "↓", "←")
action_deltas <- list(c(1,0), # up
                      c(0,1), # right
                      c(-1,0), # down
                      c(0,-1)) # left

vis_environment <- function(iterations=0, epsilon = 0.5, alpha = 0.1, gamma = 0.95, beta = 0){

  
  df <- expand.grid(x=1:H,y=1:W)
  foo <- mapply(function(x,y) ifelse(reward_map[x,y] == 0,q_table[x,y,1],NA),df$x,df$y)
  df$val1 <- as.vector(round(foo, 2))
  foo <- mapply(function(x,y) ifelse(reward_map[x,y] == 0,q_table[x,y,2],NA),df$x,df$y)
  df$val2 <- as.vector(round(foo, 2))
  foo <- mapply(function(x,y) ifelse(reward_map[x,y] == 0,q_table[x,y,3],NA),df$x,df$y)
  df$val3 <- as.vector(round(foo, 2))
  foo <- mapply(function(x,y) ifelse(reward_map[x,y] == 0,q_table[x,y,4],NA),df$x,df$y)
  df$val4 <- as.vector(round(foo, 2))
  foo <- mapply(function(x,y) 
    ifelse(reward_map[x,y] == 0,arrows[GreedyPolicy(x,y)],reward_map[x,y]),df$x,df$y)
  df$val5 <- as.vector(foo)
  foo <- mapply(function(x,y) ifelse(reward_map[x,y] == 0,max(q_table[x,y,]),
                                     ifelse(reward_map[x,y]<0,NA,reward_map[x,y])),df$x,df$y)
  df$val6 <- as.vector(foo)
  
  print(ggplot(df,aes(x = y,y = x)) +
          scale_fill_gradient(low = "white", high = "green", na.value = "red", name = "") +
          geom_tile(aes(fill=val6)) +
          geom_text(aes(label = val1),size = 4,nudge_y = .35,na.rm = TRUE) +
          geom_text(aes(label = val2),size = 4,nudge_x = .35,na.rm = TRUE) +
          geom_text(aes(label = val3),size = 4,nudge_y = -.35,na.rm = TRUE) +
          geom_text(aes(label = val4),size = 4,nudge_x = -.35,na.rm = TRUE) +
          geom_text(aes(label = val5),size = 10) +
          geom_tile(fill = 'transparent', colour = 'black') + 
          ggtitle(paste("Q-table after ",iterations," iterations\n",
                        "(epsilon = ",epsilon,", alpha = ",alpha,"gamma = ",gamma,", beta = ",beta,")")) +
          theme(plot.title = element_text(hjust = 0.5)) +
          scale_x_continuous(breaks = c(1:W),labels = c(1:W)) +
          scale_y_continuous(breaks = c(1:H),labels = c(1:H)))
  
}

GreedyPolicy <- function(x, y){

  
  foo <- which(q_table[x,y,] == max(q_table[x,y,]))
  return (ifelse(length(foo)>1,sample(foo, size = 1),foo))
  
}

EpsilonGreedyPolicy <- function(x, y, epsilon){

  
  foo <- sample(0:1,size = 1,prob = c(epsilon,1-epsilon))
  return (ifelse(foo == 1,GreedyPolicy(x,y),sample(1:4,size = 1)))
  
}

transition_model <- function(x, y, action, beta){
  delta <- sample(-1:1, size = 1, prob = c(0.5*beta,1-beta,0.5*beta))
  final_action <- ((action + delta + 3) %% 4) + 1
  foo <- c(x,y) + unlist(action_deltas[final_action])
  foo <- pmax(c(1,1),pmin(foo,c(H,W)))
  
  return (foo)
}



SARSA <- function(start_state, epsilon = 0.5, alpha = 0.1, gamma = 0.95, beta = 0){
  
  cur_pos <- start_state
  cur_action <- EpsilonGreedyPolicy(cur_pos[1], cur_pos[2], epsilon)
  episode_correction <- 0
  
  repeat{
    # Follow policy, execute action, get reward.
    new_pos <- transition_model(cur_pos[1], cur_pos[2], cur_action, beta)
    new_action <- EpsilonGreedyPolicy(new_pos[1], new_pos[2], epsilon)
    reward <- reward_map[new_pos[1], new_pos[2]]
    if(reward !=0){
       old_q <- q_table[cur_pos[1], cur_pos[2], cur_action]
       q_table[cur_pos[1], cur_pos[2], cur_action] <<- old_q + alpha*(reward-old_q)
       return (c(reward,episode_correction))
    } else {
      new_pos2 <- transition_model(new_pos[1], new_pos[2], new_action, beta)
      new_action2 <- EpsilonGreedyPolicy(new_pos2[1], new_pos2[2], epsilon)
      reward2 = reward_map[new_pos2[1], new_pos2[2]]
    
      if(reward2 !=0){
        old_q <- q_table[cur_pos[1], cur_pos[2], cur_action]
        q_table[cur_pos[1], cur_pos[2], cur_action] <<- old_q + alpha*(-1 + gamma*reward2-old_q)
        
        old_q <- q_table[new_pos[1], new_pos[2], new_action]
        q_table[new_pos[1], new_pos[2], new_action] <<- old_q + alpha*(reward2-old_q)
        return (c(reward,episode_correction))
      } else {

         old_q <- q_table[cur_pos[1], cur_pos[2], cur_action]
         q_table[cur_pos[1], cur_pos[2], cur_action] <<- old_q + alpha*(-1 + gamma*-1 + (gamma**2)*q_table[new_pos2[1], new_pos2[2], new_action2] - old_q)
         cur_pos <- new_pos
         cur_action <- new_action
         new_pos = new_pos2
         new_action = new_action2
         reward = reward2
      }
    }
  }
}

MovingAverage <- function(x, n){
  
  cx <- c(0,cumsum(x))
  rsum <- (cx[(n+1):length(cx)] - cx[1:(length(cx) - n)]) / n
  
  return (rsum)
}

H <- 3
W <- 6

reward_map <- matrix(0, nrow = H, ncol = W)
reward_map[1,2:5] <- -10
reward_map[1,6] <- 10

q_table <- array(0,dim = c(H,W,4))

rewardstr <- NULL
for(i in 1:5000){
  foo <- SARSA(start_state = c(1,1), epsilon = 0.5, gamma = 1, beta = 0)
  rewardstr <- c(rewardstr,foo[1])
}

vis_environment(5000, epsilon = 0.5, gamma = 1, beta = 0)
plot(MovingAverage(rewardstr,100),type = "l",col = "blue")

```
